{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from mosaicml import *\n",
    "from mosaicml.constants import MLModelFlavours\n",
    "from werkzeug.datastructures import FileStorage\n",
    "import pandas as pd\n",
    "import os, tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----reading data from azure\")\n",
    "storage_account_name = \"pocmosaic\"\n",
    "storage_account_access_key = \"iX6jZejeNh1bUejdSRYk+4X2S/pAbTy+idkTM5UAw2HxgxSnaYGJSN+ffzZAQ5/Q6xQe2Ja74Re9nKHMVmsGhA==\"\n",
    "file_location = \"wasbs://container1@pocmosaic.blob.core.windows.net/catalog/local_file_upload/RatanBBostonHousing.csv\"\n",
    "file_type = \"csv\"\n",
    "spark.conf.set(\"fs.azure.account.key.\"+storage_account_name+\".blob.core.windows.net\",storage_account_access_key)\n",
    "dataset = spark.read.option(\"header\", \"true\").format(file_type).option(\"inferSchema\", \"true\").load(file_location)\n",
    "dataset.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----splitting data\")\n",
    "train_data,test_data = dataset.randomSplit([0.8,0.2])\n",
    "\n",
    "print(\"-----creating pipeline\")\n",
    "stage_1 = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'Attributes')\n",
    "# define stage 5: logistic regression model                          \n",
    "stage_2 = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n",
    "\n",
    "# setup the pipeline\n",
    "regression_pipeline = Pipeline(stages= [stage_1, stage_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----training pipeline\")\n",
    "regression_pipeline = regression_pipeline.fit(train_data)\n",
    "test_update = regression_pipeline.transform(test_data)\n",
    "# test_update.show()\n",
    "\n",
    "#Predict using the model\n",
    "print(\"-----test data\")\n",
    "test_update.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define score function\n",
    "def score(model, request):\n",
    "    data = request.json\n",
    "    df = pd.DataFrame(data, columns=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat', 'medv'])\n",
    "    spark = SparkSession.builder.appName(\"jupyter-nb-test\").getOrCreate()\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    return model.transform(spark_df).toPandas()[\"prediction\"].to_json()\n",
    "\n",
    "print(\"-----defining & testing score function\")\n",
    "import requests\n",
    "req = requests.Request()\n",
    "req.json = [[1, -0.1, 0.0425, 0.0279, 2.4716, -15.2808, 4.2783, -0.0005, -1.4009, 0.2692, -0.013, -0.9905, 0.0084, -0.5533]]\n",
    "rez = score(regression_pipeline, req)\n",
    "print(\"the prediction is {}\".format(rez))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "ai_server = os.environ[\"MOSAIC_AI_SERVER\"]\n",
    "project_id = os.environ[\"PROJECT_ID\"]\n",
    "token = os.environ[\"TOKEN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%send_to_spark -i ai_server -t str -n ai_server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%send_to_spark -i project_id -t str -n project_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%send_to_spark -i token -t str -n token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MOSAIC_AI_SERVER\"] = ai_server\n",
    "os.environ[\"PROJECT_ID\"] = project_id\n",
    "os.environ[\"TOKEN\"] = token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mosaicml import *\n",
    "from mosaicml import constants\n",
    "constants.MosaicAI.server = \"http://mosaic-ai-backend:5000/registry/api\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model(regression_pipeline, score, \"Boston_Regression_Analysis_inter_july4\", \"pyspark model\", MLModelFlavours.pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
